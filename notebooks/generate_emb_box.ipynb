{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM Encoder for Image Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ictstr01/home/icb/hanyi.zhang/Detection_Head/segment-anything\n"
     ]
    }
   ],
   "source": [
    "cd /home/icb/hanyi.zhang/Detection_Head/segment-anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry\n",
    "from segment_anything.separate_sam_encoder import SamEncoder\n",
    "\n",
    "sam_checkpoint = \"/home/icb/hanyi.zhang/Detection_Head/segment-anything/sam_vit_l_0b3195.pth\"\n",
    "model_type = \"vit_l\"\n",
    "\n",
    "device = \"cuda\"\n",
    "#device = \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "sam_image_encoder = SamEncoder(sam, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def emb_images(image_folder, embed_folder, encoder):\n",
    "    \"\"\"\n",
    "    Process images to obtain embeddings and save them.\n",
    "\n",
    "    Parameters:\n",
    "    - image_folder: str, path to the folder containing source images\n",
    "    - embed_folder: str, path to the folder where embeddings will be saved\n",
    "    - encoder: the encoder object that processes images to obtain embeddings\n",
    "    \"\"\"\n",
    "    # Create the embedding directory if it doesn't exist\n",
    "    os.makedirs(embed_folder, exist_ok=True)\n",
    "    \n",
    "    # List all files in the image directory\n",
    "    images = os.listdir(image_folder)\n",
    "    \n",
    "    # Iterate over each image file\n",
    "    for i, img in enumerate(images, start=1):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i} images.\")\n",
    "        \n",
    "        # Construct full path to the image file\n",
    "        img_path = os.path.join(image_folder, img)\n",
    "        #print(img_path)\n",
    "        \n",
    "        # Load the image file and convert it to a numpy array\n",
    "        with Image.open(img_path) as image:\n",
    "            image = image.convert('RGB')\n",
    "            img_np = np.array(image)\n",
    "        \n",
    "        # Process the image to get its embedding\n",
    "        img_embed = encoder.set_image(img_np)\n",
    "        \n",
    "        # Replace the original extension with 'npy' for the output file\n",
    "        embed_path = os.path.join(embed_folder, os.path.splitext(img)[0] + '.npy')\n",
    "        \n",
    "        # Save the embedding to the specified path\n",
    "        np.save(embed_path, img_embed.cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 images.\n",
      "Processed 200 images.\n",
      "Processed 300 images.\n",
      "Processed 400 images.\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "base_folder = '/home/icb/hanyi.zhang/own_organoid_dataset'\n",
    "img_patch_dir = os.path.join(base_folder, 'image_patches_filter')\n",
    "embed_folder = os.path.join(base_folder, 'images_emb')\n",
    "emb_images(img_patch_dir, embed_folder, sam_image_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use SAM built-in function for mask coordinates processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess_boxes(mask_dir, box_dir):\n",
    "    # Create the directory\n",
    "    os.makedirs(box_dir, exist_ok=True)\n",
    "\n",
    "    processed_count = 0\n",
    "    # Loop through each file in the directory\n",
    "    for file_name in os.listdir(mask_dir):\n",
    "        label_file = np.load(os.path.join(mask_dir, file_name), allow_pickle=True)\n",
    "        transformed_coord = sam_image_encoder.set_box_coordinates(label_file)\n",
    "\n",
    "        # Normalization\n",
    "        transformed_coord = transformed_coord / 1024\n",
    "\n",
    "        # save boxes\n",
    "        np.save(os.path.join(box_dir, file_name), transformed_coord)\n",
    "\n",
    "        # Increment the counter for each augmented image\n",
    "        processed_count += 1\n",
    "        \n",
    "        # Print the number of processed images every 100 images\n",
    "        if processed_count % 100 == 0:\n",
    "            print(f\"Processed {processed_count} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 images.\n",
      "Processed 200 images.\n",
      "Processed 300 images.\n",
      "Processed 400 images.\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "base_folder = '/home/icb/hanyi.zhang/own_organoid_dataset'\n",
    "mask_dir = os.path.join(base_folder, 'label_patches_filter')\n",
    "box_dir = os.path.join(base_folder, 'bboxes')\n",
    "preprocess_boxes(mask_dir, box_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform coordinates format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def trans_boxes(ori_box_file, trans_box_dir, sam_image_encoder):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(trans_box_dir, exist_ok=True)\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(ori_box_file)\n",
    "    \n",
    "    # Group by image path to process each image separately\n",
    "    grouped = df.groupby(df.columns[0])\n",
    "    \n",
    "    # Initialize a counter for processed images\n",
    "    processed_count = 0\n",
    "    \n",
    "    for image_path, group in grouped:\n",
    "        # Extract the file name from the image path\n",
    "        file_name = os.path.basename(image_path)\n",
    "        \n",
    "        # Extract the original size from the file name\n",
    "        if '450x450' in file_name:\n",
    "            ori_size = (450, 450)\n",
    "        elif '300x300' in file_name:\n",
    "            ori_size = (300, 300)\n",
    "        else:\n",
    "            # Default or additional logic if needed\n",
    "            raise ValueError(f\"Unknown size in file name: {file_name}\")\n",
    "        \n",
    "        # Extract the bounding box coordinates as a numpy array\n",
    "        bboxes = group.iloc[:, 1:5].values\n",
    "        \n",
    "        # Transform the box coordinates using SAM's image encoder\n",
    "        transformed_coord = sam_image_encoder.trans_box_coordinates(bboxes, ori_size)\n",
    "        \n",
    "        # Normalize the transformed coordinates\n",
    "        transformed_coord = transformed_coord / 1024\n",
    "        \n",
    "        # Replace file extension with .npy\n",
    "        npy_file_name = os.path.splitext(file_name)[0] + '.npy'\n",
    "        \n",
    "        # Save the transformed coordinates as a .npy file\n",
    "        np.save(os.path.join(trans_box_dir, npy_file_name), transformed_coord)\n",
    "        \n",
    "        # Increment the counter\n",
    "        processed_count += 1\n",
    "        \n",
    "        # Print the number of processed images every 100 images\n",
    "        if processed_count % 100 == 0:\n",
    "            print(f\"Processed {processed_count} images.\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/train_labels.csv\"\n",
    "df = pd.read_csv(label_file)\n",
    "grouped = df.groupby(df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "names_labels = []\n",
    "for image_path, group in grouped:\n",
    "    i+=1\n",
    "    file_name = os.path.basename(image_path)\n",
    "    names_labels.append(file_name)\n",
    "\n",
    "names_images = os.listdir('/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/training/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all files in names_images but not in names_labels\n",
    "missing_labels = [image for image in names_images if image not in names_labels]\n",
    "\n",
    "# Save the result in a new list\n",
    "print(f\"Files in names_images but not in names_labels: {len(missing_labels)}\")\n",
    "print(missing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Assuming missing_labels is your list of missing files\n",
    "\n",
    "# Directory where the .npy files are located\n",
    "npy_dir = '/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/training/images_emb'\n",
    "\n",
    "# Replace 'jpg' with 'npy' in the missing_labels and delete the corresponding files\n",
    "for name in missing_labels:\n",
    "    npy_name = name.replace('.jpg', '.npy')\n",
    "    npy_path = os.path.join(npy_dir, npy_name)\n",
    "    \n",
    "    if os.path.exists(npy_path):\n",
    "        os.remove(npy_path)\n",
    "        print(f\"Deleted: {npy_path}\")\n",
    "    else:\n",
    "        print(f\"File not found: {npy_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/train_labels.csv\"\n",
    "output_folder = \"/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/training/boxes\"\n",
    "trans_boxes(label_file, output_folder, sam_image_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/test_labels.csv\"\n",
    "output_folder = \"/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/test/boxes\"\n",
    "trans_boxes(label_file, output_folder, sam_image_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform bboxes to the original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from typing import Tuple\n",
    "import random\n",
    "\n",
    "# Define the transformation functions\n",
    "def get_preprocess_shape(oldh: int, oldw: int, long_side_length: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Compute the output size given input size and target long side length.\n",
    "    \"\"\"\n",
    "    scale = long_side_length * 1.0 / max(oldh, oldw)\n",
    "    newh, neww = oldh * scale, oldw * scale\n",
    "    neww = int(neww + 0.5)\n",
    "    newh = int(newh + 0.5)\n",
    "    return (newh, neww)\n",
    "\n",
    "def inverse_coords(coords: np.ndarray, original_size: Tuple[int, int], target_length=1024) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse transformation of coordinates from resized back to original.\n",
    "    \"\"\"\n",
    "    old_h, old_w = original_size\n",
    "    new_h, new_w = get_preprocess_shape(old_h, old_w, target_length)\n",
    "    coords = deepcopy(coords).astype(float)\n",
    "    coords[..., 0] = coords[..., 0] * (old_w / new_w)\n",
    "    coords[..., 1] = coords[..., 1] * (old_h / new_h)\n",
    "    return coords\n",
    "\n",
    "def inverse_boxes(boxes: np.ndarray, original_size: Tuple[int, int], target_length=1024) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse transformation of boxes from resized back to original.\n",
    "    \"\"\"\n",
    "    boxes = inverse_coords(boxes.reshape(-1, 2, 2), original_size, target_length)\n",
    "    return boxes.reshape(-1, 4)\n",
    "\n",
    "def convert_boxes(boxes):\n",
    "    # Convert the boxes from center format to [y_min, x_min, y_max, x_max] format\n",
    "    converted_boxes = np.zeros_like(boxes)\n",
    "    converted_boxes[:, 0] = boxes[:, 1] - boxes[:, 3] / 2.0  # x_min\n",
    "    converted_boxes[:, 1] = boxes[:, 0] - boxes[:, 2] / 2.0  # y_min\n",
    "    converted_boxes[:, 2] = boxes[:, 1] + boxes[:, 3] / 2.0  # x_max\n",
    "    converted_boxes[:, 3] = boxes[:, 0] + boxes[:, 2] / 2.0  # y_max\n",
    "    return converted_boxes\n",
    "\n",
    "img_folder = '/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/training/images'\n",
    "box_folder = '/home/icb/hanyi.zhang/public_organoid_datasets/OrgaQuant_DeepOrga_dataset/Intestinal_Organoid_Dataset/training/boxes'\n",
    "\n",
    "img_name = random.choice(os.listdir(img_folder))\n",
    "img = Image.open(os.path.join(img_folder, img_name))\n",
    "box = np.load(os.path.join(box_folder, img_name.replace('jpg', 'npy')))\n",
    "\n",
    "img_np = np.array(img)\n",
    "\n",
    "original_size = img.size  # (width, height)\n",
    "original_size = (original_size[1], original_size[0])  # Convert to (height, width)\n",
    "\n",
    "original_boxes = inverse_boxes(convert_boxes(box) * 1024, original_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Convert the image back to (height, width) format for plotting\n",
    "img_np = np.array(img)\n",
    "\n",
    "# Plot the image\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(img_np)\n",
    "\n",
    "# Plot each bounding box\n",
    "for box in original_boxes:\n",
    "    # The coordinates of the box are in [y_min, x_min, y_max, x_max] format\n",
    "    y_min, x_min, y_max, x_max = box\n",
    "    \n",
    "    # Calculate width and height of the box\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    \n",
    "    # Create a rectangle patch\n",
    "    rect = patches.Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    \n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem_kernel",
   "language": "python",
   "name": "mem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
