{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SAM checkpoint for image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/icb/hanyi.zhang/Detection_Head/segment-anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from segment_anything.separate_sam_encoder import SamEncoder\n",
    "import torch\n",
    "\n",
    "sam_checkpoint = \"/home/icb/hanyi.zhang/Detection_Head/segment-anything/sam_vit_l_0b3195.pth\"\n",
    "model_type = \"vit_l\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "sam_image_encoder = SamEncoder(sam, device)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define necessary functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "from typing import Tuple\n",
    "\n",
    "def emb_images(image_folder, embed_folder, encoder):\n",
    "    \"\"\"\n",
    "    Process images to obtain embeddings and save them.\n",
    "\n",
    "    Parameters:\n",
    "    - image_folder: str, path to the folder containing source images\n",
    "    - embed_folder: str, path to the folder where embeddings will be saved\n",
    "    - encoder: the encoder object that processes images to obtain embeddings\n",
    "    \"\"\"\n",
    "    # Create the embedding directory if it doesn't exist\n",
    "    os.makedirs(embed_folder, exist_ok=True)\n",
    "    \n",
    "    # List all files in the image directory\n",
    "    images = os.listdir(image_folder)\n",
    "\n",
    "    # Iterate over each image file\n",
    "    for i, img in enumerate(images, start=1):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i} images.\")\n",
    "        \n",
    "        # Construct full path to the image file\n",
    "        img_path = os.path.join(image_folder, img)\n",
    "        \n",
    "        # Load the image file and convert it to a numpy array\n",
    "        with Image.open(img_path) as image:\n",
    "            image = image.convert('RGB')\n",
    "            img_np = np.array(image)\n",
    "        \n",
    "        # Process the image to get its embedding\n",
    "        img_embed = encoder.set_image(img_np)\n",
    "        \n",
    "        # Replace the original extension with 'npy' for the output file\n",
    "        embed_path = os.path.join(embed_folder, img.replace('.png', '.npy'))\n",
    "        \n",
    "        # Save the embedding to the specified path\n",
    "        np.save(embed_path, img_embed.cpu().detach().numpy())\n",
    "\n",
    "# Function to load checkpoint and perform evaluation on one example\n",
    "def evaluate_single_example(model, img_emb):\n",
    "    # Prepare the input\n",
    "    img_emb = torch.tensor(img_emb, dtype=torch.float32).to(device)  # Convert and move to GPU if available\n",
    "    \n",
    "    # Dummy query embedding (you may adjust this based on your actual implementation)\n",
    "    query_embed = model.query_embed.weight.to(device)\n",
    "    \n",
    "    # Get positional embedding\n",
    "    pos_embedding = model.position_embedding(img_emb)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(query_embedding=query_embed, image_embedding=img_emb, pos_embedding=pos_embedding)\n",
    "\n",
    "    # Apply softmax to pred_logits\n",
    "    pred_logits = torch.nn.functional.softmax(outputs['pred_logits'][0], dim=-1)\n",
    "    \n",
    "    # Convert softmax output to binary predictions (0 or 1)\n",
    "    binary_predictions = (pred_logits[:, 0] > pred_logits[:, 1]).cpu().numpy().astype(int)\n",
    "    \n",
    "    # Filter out boxes with binary prediction value 0\n",
    "    pred_boxes = outputs['pred_boxes'].cpu().numpy()[0]\n",
    "    filtered_boxes = pred_boxes[binary_predictions == 1]\n",
    "    confidence_scores = pred_logits[binary_predictions == 1, 0].cpu().numpy()\n",
    "    \n",
    "    return filtered_boxes, confidence_scores\n",
    "\n",
    "def evaluate_single_example_given_threshold(model, img_emb, confidence_threshold):\n",
    "    # Prepare the input\n",
    "    img_emb = torch.tensor(img_emb, dtype=torch.float32).to(device)  # Convert and move to GPU if available\n",
    "    \n",
    "    # Dummy query embedding (you may adjust this based on your actual implementation)\n",
    "    query_embed = model.query_embed.weight.to(device)\n",
    "    \n",
    "    # Get positional embedding\n",
    "    pos_embedding = model.position_embedding(img_emb)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(query_embedding=query_embed, image_embedding=img_emb, pos_embedding=pos_embedding)\n",
    "\n",
    "    # Apply softmax to pred_logits\n",
    "    pred_logits = torch.nn.functional.softmax(outputs['pred_logits'][0], dim=-1)\n",
    "    \n",
    "    # Convert softmax output to binary predictions (0 or 1) based on the confidence score threshold\n",
    "    binary_predictions = (pred_logits[:, 0] > torch.tensor(confidence_threshold)).cpu().numpy().astype(int)\n",
    "    \n",
    "    # Filter out boxes with binary prediction value 0\n",
    "    pred_boxes = outputs['pred_boxes'].cpu().numpy()[0]\n",
    "    filtered_boxes = pred_boxes[binary_predictions == 1]\n",
    "    confidence_scores = pred_logits[binary_predictions == 1, 0].cpu().numpy()\n",
    "    \n",
    "    return filtered_boxes, confidence_scores\n",
    "\n",
    "def non_max_suppression(bboxes, scores, threshold):\n",
    "    \"\"\"Perform Non-Maximum Suppression (NMS) on bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "    bboxes (numpy.ndarray): Array of bounding boxes in the format (x1, y1, x2, y2).\n",
    "    scores (numpy.ndarray): Array of scores for each bounding box.\n",
    "    threshold (float): IoU threshold for suppression.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of indices of bounding boxes to keep.\n",
    "    \"\"\"\n",
    "    # Sort the bounding boxes by the scores in descending order\n",
    "    indices = np.argsort(scores)[::-1]\n",
    "    \n",
    "    keep = []\n",
    "    while len(indices) > 0:\n",
    "        current = indices[0]\n",
    "        keep.append(current)\n",
    "        \n",
    "        if len(indices) == 1:\n",
    "            break\n",
    "        \n",
    "        current_box = bboxes[current]\n",
    "        remaining_boxes = bboxes[indices[1:]]\n",
    "        \n",
    "        # Compute IoU of the current box with the rest\n",
    "        ious = np.array([compute_iou_box(current_box, box) for box in remaining_boxes])\n",
    "        \n",
    "        # Select boxes with IoU less than the threshold\n",
    "        indices = indices[1:][ious < threshold]\n",
    "    \n",
    "    return np.array(keep)\n",
    "\n",
    "def compute_iou_box(box1, box2):\n",
    "    x1_max = max(box1[0], box2[0])\n",
    "    y1_max = max(box1[1], box2[1])\n",
    "    x2_min = min(box1[2], box2[2])\n",
    "    y2_min = min(box1[3], box2[3])\n",
    "\n",
    "    intersection_area = max(0, x2_min - x1_max) * max(0, y2_min - y1_max)\n",
    "\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "# Define the transformation functions\n",
    "def get_preprocess_shape(oldh: int, oldw: int, long_side_length: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Compute the output size given input size and target long side length.\n",
    "    \"\"\"\n",
    "    scale = long_side_length * 1.0 / max(oldh, oldw)\n",
    "    newh, neww = oldh * scale, oldw * scale\n",
    "    neww = int(neww + 0.5)\n",
    "    newh = int(newh + 0.5)\n",
    "    return (newh, neww)\n",
    "\n",
    "def inverse_coords(coords: np.ndarray, original_size: Tuple[int, int], target_length=1024) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse transformation of coordinates from resized back to original.\n",
    "    \"\"\"\n",
    "    old_h, old_w = original_size\n",
    "    new_h, new_w = get_preprocess_shape(old_h, old_w, target_length)\n",
    "    coords = deepcopy(coords).astype(float)\n",
    "    coords[..., 0] = coords[..., 0] * (old_w / new_w)\n",
    "    coords[..., 1] = coords[..., 1] * (old_h / new_h)\n",
    "    return coords\n",
    "\n",
    "def inverse_boxes(boxes: np.ndarray, original_size: Tuple[int, int], target_length=1024) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse transformation of boxes from resized back to original.\n",
    "    \"\"\"\n",
    "    boxes = inverse_coords(boxes.reshape(-1, 2, 2), original_size, target_length)\n",
    "    return boxes.reshape(-1, 4)\n",
    "\n",
    "def convert_boxes(boxes):\n",
    "    # Convert the boxes from center format to [x_min, y_min, x_max, y_max] format\n",
    "    converted_boxes = np.zeros_like(boxes)\n",
    "    converted_boxes[:, 0] = boxes[:, 1] - boxes[:, 3] / 2.0  # x_min\n",
    "    converted_boxes[:, 1] = boxes[:, 0] - boxes[:, 2] / 2.0  # y_min\n",
    "    converted_boxes[:, 2] = boxes[:, 1] + boxes[:, 3] / 2.0  # x_max\n",
    "    converted_boxes[:, 3] = boxes[:, 0] + boxes[:, 2] / 2.0  # y_max\n",
    "    return converted_boxes\n",
    "\n",
    "def transform_mask(mask):\n",
    "    \"\"\"\n",
    "    Transforms a mask of shape (N, 1, H, W) into a single mask of shape (H, W),\n",
    "    where background is 0 and different masks are labeled as 1, 2, 3, ..., N.\n",
    "    If the mask contains only zeros, it returns a zero-filled mask of shape (H, W).\n",
    "    \"\"\"\n",
    "    # Check if the mask is entirely zeros\n",
    "    if len(mask.shape) == 2:\n",
    "        return mask\n",
    "\n",
    "    # Get the number of masks\n",
    "    num_masks = mask.shape[0]\n",
    "    \n",
    "    # Initialize a new mask with zeros (background)\n",
    "    transformed_mask = np.zeros((mask.shape[2], mask.shape[3]), dtype=np.uint8)\n",
    "\n",
    "    # Assign label 1, 2, 3, ..., N to each mask respectively\n",
    "    for i in range(num_masks):\n",
    "        single_mask = mask[i, 0, :, :]  # Extract each mask\n",
    "        transformed_mask[single_mask > 0] = i + 1  # Label the mask with 1, 2, ..., N\n",
    "\n",
    "    return transformed_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please uncomment the following cell if image embeddings are unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''embed_folder = '/home/icb/hanyi.zhang/public_organoid_datasets/OrganoID_dataset/testing/images_sam_emb'\n",
    "emb_images(images_path, embed_folder, sam_image_encoder)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load detection head checkpoint for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/icb/hanyi.zhang/Detection_Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint here\n",
    "from detection_head_model import DetectionHead\n",
    "import torch\n",
    "\n",
    "#checkpoint_path = '/home/icb/hanyi.zhang/Detection_Head/checkpoints/DetectionHead_finetuning-epoch=599-val_loss=7.82.ckpt'\n",
    "#checkpoint_path = '/home/icb/hanyi.zhang/Detection_Head/checkpoints/DetectionHead_training-orga-epoch=599-val_loss=8.23.ckpt'\n",
    "checkpoint_path = '/home/icb/hanyi.zhang/Detection_Head/checkpoints/DetectionHead_fine_tuning_combined-epoch=599-val_loss=7.38.ckpt'\n",
    "\n",
    "model = DetectionHead.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Determine device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of trainable parameters in Mio (millions)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params / 1e6:.2f} Mio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths to the folder containing images and image embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define paths\n",
    "base_path = '/home/icb/hanyi.zhang/MouseOrganoids/testing_PDAC'\n",
    "\n",
    "img_folder = base_path + '/images'\n",
    "img_emb_folder = base_path + '/images_emb'\n",
    "\n",
    "# Define paths to save the predicted masks and bboxes\n",
    "predictions_save_path = base_path + '/pred_mask_th'\n",
    "bboxes_save_path = base_path + '/pred_bbox_th'\n",
    "\n",
    "# Define confidence score threshold\n",
    "confidence_score = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(predictions_save_path, exist_ok=True)\n",
    "os.makedirs(bboxes_save_path, exist_ok=True)\n",
    "\n",
    "print(img_folder)\n",
    "\n",
    "# Get list of files\n",
    "img_emb_files = os.listdir(img_emb_folder)\n",
    "\n",
    "# NMS threshold\n",
    "threshold = 0.5\n",
    "\n",
    "for img_emb_file in img_emb_files:\n",
    "    file_idx = img_emb_file.rsplit('.', 1)[0]\n",
    "    print(file_idx)\n",
    "\n",
    "    # Define image path, label path and image embedding path\n",
    "    image_path = os.path.join(img_folder, file_idx + '.png')\n",
    "    image_embedding_path = os.path.join(img_emb_folder, img_emb_file)\n",
    "    mask_save_path = os.path.join(predictions_save_path, file_idx + '.npy')\n",
    "    bbox_save_path = os.path.join(bboxes_save_path, file_idx + '.npy')\n",
    "\n",
    "    # Read the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Get the original size of the image\n",
    "    original_size = image.size  # (width, height)\n",
    "    original_size = (original_size[1], original_size[0])  # Convert to (height, width)\n",
    "\n",
    "    # Load image embedding\n",
    "    image_embedding = np.load(image_embedding_path)\n",
    "\n",
    "    # Predict boxes and convert to original size\n",
    "    #predicted_boxes, confidence_scores = evaluate_single_example(model, image_embedding)\n",
    "    predicted_boxes, confidence_scores = evaluate_single_example_given_threshold(model, image_embedding, confidence_score)\n",
    "    original_boxes_pred = inverse_boxes(convert_boxes(predicted_boxes) * 1024, original_size)\n",
    "        \n",
    "    kept_indices = non_max_suppression(original_boxes_pred, confidence_scores, threshold)\n",
    "    if len(kept_indices) != 0:\n",
    "        original_boxes_pred_filtered = original_boxes_pred[kept_indices]\n",
    "        filtered_confidences = confidence_scores[kept_indices]\n",
    "        \n",
    "        # Predict masks\n",
    "        image = cv2.imread(image_path)\n",
    "        predictor.set_image(image)\n",
    "        input_boxes = torch.tensor(original_boxes_pred_filtered).to(device)\n",
    "        transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])\n",
    "        masks, _, _ = predictor.predict_torch(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            boxes=transformed_boxes,\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        predicted_masks = masks.cpu().numpy()\n",
    "        predicted_masks = transform_mask(predicted_masks)\n",
    "\n",
    "        # Save the bounding boxes\n",
    "        np.save(bbox_save_path, original_boxes_pred_filtered)\n",
    "    else:\n",
    "        # If no boxes, create an all-zero mask and save empty bounding boxes\n",
    "        predicted_masks = np.zeros((original_size[0], original_size[1]), dtype=np.uint8)\n",
    "        np.save(bbox_save_path, np.array([]))  # Save empty array for bounding boxes\n",
    "\n",
    "    # Save the mask\n",
    "    np.save(mask_save_path, predicted_masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute metric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from skimage.measure import label\n",
    "\n",
    "def compute_iou(pred_mask, gt_mask, pred_label, gt_label):\n",
    "    pred_instance = (pred_mask == pred_label)\n",
    "    gt_instance = (gt_mask == gt_label)\n",
    "    \n",
    "    intersection = np.logical_and(pred_instance, gt_instance).sum()\n",
    "    union = np.logical_or(pred_instance, gt_instance).sum()\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return intersection / union\n",
    "\n",
    "def compute_metrics(pred_mask, gt_mask, iou_threshold=0.5):\n",
    "    pred_labels = np.unique(pred_mask)\n",
    "    gt_labels = np.unique(gt_mask)\n",
    "    \n",
    "    # Remove background label (0)\n",
    "    pred_labels = pred_labels[pred_labels != 0]\n",
    "    gt_labels = gt_labels[gt_labels != 0]\n",
    "    \n",
    "    num_preds = len(pred_labels)\n",
    "    num_gts = len(gt_labels)\n",
    "    \n",
    "    # Create the IoU matrix\n",
    "    iou_matrix = np.zeros((num_preds, num_gts))\n",
    "    \n",
    "    for i, p_label in enumerate(pred_labels):\n",
    "        for j, g_label in enumerate(gt_labels):\n",
    "            iou_matrix[i, j] = compute_iou(pred_mask, gt_mask, p_label, g_label)\n",
    "    \n",
    "    # Hungarian matching\n",
    "    row_ind, col_ind = linear_sum_assignment(-iou_matrix)\n",
    "    \n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    \n",
    "    matched_gt = set()\n",
    "    matched_pred = set()\n",
    "    \n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        if iou_matrix[i, j] >= iou_threshold:\n",
    "            tp.append(iou_matrix[i, j])\n",
    "            matched_gt.add(j)\n",
    "            matched_pred.add(i)\n",
    "    \n",
    "    for i in range(num_preds):\n",
    "        if i not in matched_pred:\n",
    "            fp.append(pred_labels[i])\n",
    "    \n",
    "    for j in range(num_gts):\n",
    "        if j not in matched_gt:\n",
    "            fn.append(gt_labels[j])\n",
    "    \n",
    "    # Calculate PQ\n",
    "    pq = np.sum(tp) / (len(tp) + 0.5 * len(fp) + 0.5 * len(fn))\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = len(tp) / (len(tp) + len(fp)) if (len(tp) + len(fp)) > 0 else 0\n",
    "    recall = len(tp) / (len(tp) + len(fn)) if (len(tp) + len(fn)) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Calculate mean IoU\n",
    "    mean_iou = np.mean(tp) if len(tp) > 0 else 0\n",
    "    \n",
    "    # Calculate Dice coefficient\n",
    "    dice_coefficient = np.mean([2 * iou / (1 + iou) for iou in tp]) if len(tp) > 0 else 0\n",
    "    \n",
    "    return len(tp), len(fp), len(fn), pq, precision, recall, f1_score, mean_iou, dice_coefficient\n",
    "\n",
    "def process_folder(pred_folder, gt_folder, mask_need_transform, iou_threshold=0.5):\n",
    "    pred_files = sorted(os.listdir(pred_folder))\n",
    "    gt_files = sorted(os.listdir(gt_folder))\n",
    "    \n",
    "    pq_values = []\n",
    "    precision_values = []\n",
    "    recall_values = []\n",
    "    f1_score_values = []\n",
    "    mean_iou_values = []\n",
    "    dice_values = []\n",
    "\n",
    "    for i, (pred_file, gt_file) in enumerate(zip(pred_files, gt_files)):\n",
    "        print(pred_file)\n",
    "        pred_mask = np.load(os.path.join(pred_folder, pred_file))\n",
    "        if mask_need_transform:\n",
    "            pred_mask = transform_mask(pred_mask)\n",
    "        gt_mask = np.load(os.path.join(gt_folder, gt_file))\n",
    "        \n",
    "        tp, fp, fn, pq, precision, recall, f1_score, mean_iou, dice_coefficient = compute_metrics(pred_mask, gt_mask, iou_threshold)\n",
    "        \n",
    "        pq_values.append(pq)\n",
    "        precision_values.append(precision)\n",
    "        recall_values.append(recall)\n",
    "        f1_score_values.append(f1_score)\n",
    "        mean_iou_values.append(mean_iou)\n",
    "        dice_values.append(dice_coefficient)\n",
    "        #print(mean_iou)\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} files\")\n",
    "    \n",
    "    pq_values = np.array(pq_values)\n",
    "    precision_values = np.array(precision_values)\n",
    "    recall_values = np.array(recall_values)\n",
    "    f1_score_values = np.array(f1_score_values)\n",
    "    mean_iou_values = np.array(mean_iou_values)\n",
    "    dice_values = np.array(dice_values)\n",
    "    \n",
    "    metrics = {\n",
    "        \"mean_pq\": np.mean(pq_values),\n",
    "        \"mean_precision\": np.mean(precision_values),\n",
    "        \"mean_recall\": np.mean(recall_values),\n",
    "        \"mean_f1_score\": np.mean(f1_score_values),\n",
    "        \"mean_iou\": np.mean(mean_iou_values),\n",
    "        \"mean_dice_coefficient\": np.mean(dice_values)\n",
    "    }\n",
    "    \n",
    "    return metrics, pq_values, precision_values, recall_values, f1_score_values, mean_iou_values, dice_values\n",
    "\n",
    "# Function to save metrics to files\n",
    "def save_metrics(metrics, pq_values, precision_values, recall_values, f1_score_values, mean_iou_values, dice_values, output_folder):\n",
    "    # Create the output folder if it does not exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Save each array as a .npy file\n",
    "    np.save(os.path.join(output_folder, 'pq_values.npy'), pq_values)\n",
    "    np.save(os.path.join(output_folder, 'precision_values.npy'), precision_values)\n",
    "    np.save(os.path.join(output_folder, 'recall_values.npy'), recall_values)\n",
    "    np.save(os.path.join(output_folder, 'f1_score_values.npy'), f1_score_values)\n",
    "    np.save(os.path.join(output_folder, 'mean_iou_values.npy'), mean_iou_values)\n",
    "    np.save(os.path.join(output_folder, 'dice_values.npy'), dice_values)\n",
    "    \n",
    "    # Save the overall metrics as a text file\n",
    "    with open(os.path.join(output_folder, 'overall_metrics.txt'), 'w') as f:\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            f.write(f\"{metric_name}: {metric_value}\\n\")\n",
    "\n",
    "# Function to process and save metrics\n",
    "def process_and_save_metrics(pred_folder, gt_folder, output_folder):\n",
    "    # Compute the mean PQ and log individual PQ values\n",
    "    metrics, pq_values, precision_values, recall_values, f1_score_values, mean_iou_values, dice_values = process_folder(pred_folder, gt_folder, mask_need_transform=False)\n",
    "\n",
    "    # Print all metrics\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"{metric_name}: {metric_value}\")\n",
    "    \n",
    "    # Save the metrics to the specified folder\n",
    "    save_metrics(metrics, pq_values, precision_values, recall_values, f1_score_values, mean_iou_values, dice_values, output_folder)\n",
    "    print(f\"Metrics and values saved to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths to predicted masks and ground truth masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/home/icb/hanyi.zhang/public_organoid_datasets/OrganoID_dataset/testing'\n",
    "\n",
    "gt_mask_dir = os.path.join(base_folder, 'segmentations_npy')\n",
    "pred_mask_dir = os.path.join(base_folder, 'pred_mask')\n",
    "\n",
    "# Specify the output folder for saving metrics\n",
    "output_folder = os.path.join(base_folder, 'scratch_metrics_values_our')\n",
    "\n",
    "process_and_save_metrics(pred_mask_dir, gt_mask_dir, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define paths\n",
    "base_path = '/home/icb/hanyi.zhang/public_organoid_datasets/OrganoID_dataset/testing_PDAC'\n",
    "\n",
    "img_folder = base_path + '/images'\n",
    "img_emb_folder = base_path + '/images_emb'\n",
    "\n",
    "# Define confidence score threshold\n",
    "confidence_score = np.arange(0.0, 1.05, 0.05)\n",
    "\n",
    "for c_score in confidence_score:\n",
    "    # Define paths to save the predicted masks and bboxes\n",
    "    predictions_save_path = base_path + '/pred_mask_th_' + str(c_score)\n",
    "    bboxes_save_path = base_path + '/pred_bbox_th_'  + str(c_score)\n",
    "\n",
    "    os.makedirs(predictions_save_path, exist_ok=True)\n",
    "    os.makedirs(bboxes_save_path, exist_ok=True)\n",
    "\n",
    "    print(c_score)\n",
    "\n",
    "    # Get list of files\n",
    "    img_emb_files = os.listdir(img_emb_folder)\n",
    "\n",
    "    # NMS threshold\n",
    "    threshold = 0.5\n",
    "\n",
    "    for img_emb_file in img_emb_files:\n",
    "        file_idx = img_emb_file.rsplit('.', 1)[0]\n",
    "        print(file_idx)\n",
    "\n",
    "        # Define image path, label path and image embedding path\n",
    "        image_path = os.path.join(img_folder, file_idx + '.png')\n",
    "        image_embedding_path = os.path.join(img_emb_folder, img_emb_file)\n",
    "        mask_save_path = os.path.join(predictions_save_path, file_idx + '.npy')\n",
    "        bbox_save_path = os.path.join(bboxes_save_path, file_idx + '.npy')\n",
    "\n",
    "        # Read the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Get the original size of the image\n",
    "        original_size = image.size  # (width, height)\n",
    "        original_size = (original_size[1], original_size[0])  # Convert to (height, width)\n",
    "\n",
    "        # Load image embedding\n",
    "        image_embedding = np.load(image_embedding_path)\n",
    "\n",
    "        # Predict boxes and convert to original size\n",
    "        #predicted_boxes, confidence_scores = evaluate_single_example(model, image_embedding)\n",
    "        predicted_boxes, confidence_scores = evaluate_single_example_given_threshold(model, image_embedding, c_score)\n",
    "        original_boxes_pred = inverse_boxes(convert_boxes(predicted_boxes) * 1024, original_size)\n",
    "            \n",
    "        kept_indices = non_max_suppression(original_boxes_pred, confidence_scores, threshold)\n",
    "        if len(kept_indices) != 0:\n",
    "            original_boxes_pred_filtered = original_boxes_pred[kept_indices]\n",
    "            filtered_confidences = confidence_scores[kept_indices]\n",
    "            \n",
    "            # Predict masks\n",
    "            image = cv2.imread(image_path)\n",
    "            predictor.set_image(image)\n",
    "            input_boxes = torch.tensor(original_boxes_pred_filtered).to(device)\n",
    "            transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])\n",
    "            masks, _, _ = predictor.predict_torch(\n",
    "                point_coords=None,\n",
    "                point_labels=None,\n",
    "                boxes=transformed_boxes,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "            predicted_masks = masks.cpu().numpy()\n",
    "            predicted_masks = transform_mask(predicted_masks)\n",
    "\n",
    "            # Save the bounding boxes\n",
    "            np.save(bbox_save_path, original_boxes_pred_filtered)\n",
    "        else:\n",
    "            # If no boxes, create an all-zero mask and save empty bounding boxes\n",
    "            predicted_masks = np.zeros((original_size[0], original_size[1]), dtype=np.uint8)\n",
    "            np.save(bbox_save_path, np.array([]))  # Save empty array for bounding boxes\n",
    "\n",
    "        # Save the mask\n",
    "        np.save(mask_save_path, predicted_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base folder\n",
    "base_folder = '/home/icb/hanyi.zhang/public_organoid_datasets/OrganoID_dataset/testing_PDAC'\n",
    "\n",
    "# Define confidence score thresholds\n",
    "confidence_scores = np.arange(0.0, 1.05, 0.05)\n",
    "\n",
    "# Initialize lists to store mean values\n",
    "pq = []\n",
    "pre = []\n",
    "recall = []\n",
    "f1 = []\n",
    "iou = []\n",
    "dice = []\n",
    "\n",
    "# Folder to save results\n",
    "output_folder = os.path.join(base_folder, 'confidence_score_metrics')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each confidence score and record metrics\n",
    "for c_score in confidence_scores:\n",
    "    gt_mask_dir = os.path.join(base_folder, 'segmentations_npy')\n",
    "    pred_mask_dir = os.path.join(base_folder, 'pred_mask_th_'  + str(c_score))\n",
    "    \n",
    "    # Get metrics from process_folder function\n",
    "    metrics, pq_values, precision_values, recall_values, f1_score_values, mean_iou_values, dice_values = process_folder(\n",
    "        pred_mask_dir, gt_mask_dir, mask_need_transform=False\n",
    "    )\n",
    "    \n",
    "    # Record mean values for each metric\n",
    "    pq.append(np.mean(pq_values))\n",
    "    pre.append(np.mean(precision_values))\n",
    "    recall.append(np.mean(recall_values))\n",
    "    f1.append(np.mean(f1_score_values))\n",
    "    iou.append(np.mean(mean_iou_values))\n",
    "    dice.append(np.mean(dice_values))\n",
    "\n",
    "# Save the lists to the output folder\n",
    "np.save(os.path.join(output_folder, 'pq.npy'), pq)\n",
    "np.save(os.path.join(output_folder, 'precision.npy'), pre)\n",
    "np.save(os.path.join(output_folder, 'recall.npy'), recall)\n",
    "np.save(os.path.join(output_folder, 'f1.npy'), f1)\n",
    "np.save(os.path.join(output_folder, 'iou.npy'), iou)\n",
    "np.save(os.path.join(output_folder, 'dice.npy'), dice)\n",
    "\n",
    "# Plot F1 score vs. Confidence Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(confidence_scores, f1, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel(\"Confidence Score\")\n",
    "plt.ylabel(\"Mean F1 Score\")\n",
    "plt.title(\"F1 Score vs. Confidence Score Threshold\")\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_folder, 'f1_score_vs_confidence_score.png'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mem_kernel",
   "language": "python",
   "name": "mem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
